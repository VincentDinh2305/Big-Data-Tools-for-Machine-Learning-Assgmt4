{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dinh Hoang Viet Phuong - 301123263"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Research and investigate the LIBSVM format, in your analysis report define the format and show an example with explanation (in Report)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Load the data stored in the file “sample_libsvm_data.txt” from the data available on the VMware image under the directory /home/centos/data/ into a dataframe and name it df_x where x is your firstname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"LIBSVM Data Loading\").getOrCreate()\n",
    "\n",
    "# Path to your LIBSVM file\n",
    "file_path = \"/home/centos/data/sample_libsvm_data.txt\"\n",
    "\n",
    "# Read the LIBSVM file\n",
    "df_phuong = spark.read.format(\"libsvm\").load(file_path)\n",
    "\n",
    "# Show the DataFrame\n",
    "df_phuong.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Carry out some basic investigation: count the number of records, count the number of columns print the inferred schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Records: 100\n",
      "Number of Columns: 2\n",
      "Inferred Schema:\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of records\n",
    "num_records = df_phuong.count()\n",
    "print(f\"Number of Records: {num_records}\")\n",
    "\n",
    "# Count the number of columns\n",
    "num_columns = len(df_phuong.columns)\n",
    "print(f\"Number of Columns: {num_columns}\")\n",
    "\n",
    "# Print the inferred schema\n",
    "print(\"Inferred Schema:\")\n",
    "df_phuong.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Use the StringIndexer to index labels, in other words you will add metadata to the label column. Name the output column \"indexedLabel_phuong”. Store the result in a variable named labelIndexer_phuong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Create an instance of the StringIndexer\n",
    "labelIndexer_phuong = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel_phuong\")\n",
    "\n",
    "# Fit the StringIndexer to the data and transform it\n",
    "df_indexed = labelIndexer_phuong.fit(df_phuong).transform(df_phuong)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Use the VectorIndexer to automatically identify categorical features, and index them. Set the maxCategories to 4. Name the output column \" indexedFeatures _phuong. Store the result in a variable named featureIndexer _phuong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------------------+\n",
      "|label|            features|indexedFeatures_phuong|\n",
      "+-----+--------------------+----------------------+\n",
      "|  0.0|(692,[127,128,129...|  (692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|  (692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|  (692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|  (692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|  (692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|  (692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|  (692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|  (692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|  (692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|  (692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|  (692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|  (692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|  (692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|  (692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|  (692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|  (692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|  (692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|  (692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|  (692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|  (692,[124,125,126...|\n",
      "+-----+--------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "# Create an instance of the VectorIndexer\n",
    "featureIndexer_phuong = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures_phuong\", maxCategories=4, handleInvalid=\"skip\")\n",
    "\n",
    "# Fit the VectorIndexer to the data and transform it\n",
    "df_indexed_features = featureIndexer_phuong.fit(df_phuong).transform(df_phuong)\n",
    "\n",
    "# Show the transformed DataFrame\n",
    "df_indexed_features.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Printout the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Input Column: features\n",
      "Name of Output Column: indexedFeatures_phuong\n",
      "Number of Features: 692\n",
      "Map of Categories:\n",
      "{645: {0.0: 0}, 69: {0.0: 0}, 365: {0.0: 0}, 138: {0.0: 0}, 479: {0.0: 0}, 333: {0.0: 0}, 249: {0.0: 0}, 0: {0.0: 0}, 666: {0.0: 0, 10.0: 1}, 88: {0.0: 0}, 170: {0.0: 0}, 115: {0.0: 0}, 276: {0.0: 0, 3.0: 1, 153.0: 2, 252.0: 3}, 308: {0.0: 0}, 5: {0.0: 0}, 449: {0.0: 0}, 120: {0.0: 0, 253.0: 1}, 614: {0.0: 0, 140.0: 1}, 677: {0.0: 0}, 202: {0.0: 0, 13.0: 1, 44.0: 2, 87.0: 3}, 10: {0.0: 0}, 56: {0.0: 0}, 533: {0.0: 0}, 142: {0.0: 0}, 340: {0.0: 0}, 670: {0.0: 0}, 174: {0.0: 0, 175.0: 1}, 42: {0.0: 0}, 417: {0.0: 0}, 24: {0.0: 0}, 37: {0.0: 0}, 25: {0.0: 0}, 257: {0.0: 0, 73.0: 1, 120.0: 2}, 389: {0.0: 0}, 52: {0.0: 0}, 14: {0.0: 0}, 504: {0.0: 0}, 110: {0.0: 0}, 587: {0.0: 0}, 619: {0.0: 0}, 196: {0.0: 0}, 559: {0.0: 0}, 638: {0.0: 0, 1.0: 1, 29.0: 2, 137.0: 3}, 20: {0.0: 0}, 421: {0.0: 0}, 46: {0.0: 0}, 93: {0.0: 0}, 284: {0.0: 0}, 228: {0.0: 0}, 448: {0.0: 0}, 57: {0.0: 0}, 78: {0.0: 0}, 29: {0.0: 0}, 475: {0.0: 0}, 164: {0.0: 0, 14.0: 1}, 591: {0.0: 0}, 646: {0.0: 0}, 253: {0.0: 0}, 106: {0.0: 0}, 121: {0.0: 0, 63.0: 1, 132.0: 2}, 84: {0.0: 0}, 147: {0.0: 0, 241.0: 1}, 280: {0.0: 0}, 61: {0.0: 0}, 221: {0.0: 0}, 396: {0.0: 0, 19.0: 1}, 89: {0.0: 0}, 133: {0.0: 0, 9.0: 1, 18.0: 2, 52.0: 3}, 116: {0.0: 0}, 1: {0.0: 0}, 507: {0.0: 0}, 312: {0.0: 0}, 74: {0.0: 0}, 307: {0.0: 0}, 452: {0.0: 0, 24.0: 1, 29.0: 2}, 6: {0.0: 0}, 248: {0.0: 0, 13.0: 1, 250.0: 2}, 60: {0.0: 0}, 117: {0.0: 0}, 678: {0.0: 0, 37.0: 1, 40.0: 2}, 529: {0.0: 0}, 85: {0.0: 0}, 201: {0.0: 0}, 220: {0.0: 0, 250.0: 1}, 366: {0.0: 0}, 534: {0.0: 0}, 102: {0.0: 0, 5.0: 1, 72.0: 2}, 334: {0.0: 0}, 28: {0.0: 0}, 38: {0.0: 0}, 561: {0.0: 0}, 392: {0.0: 0}, 70: {0.0: 0}, 424: {0.0: 0, 5.0: 1, 29.0: 2}, 192: {0.0: 0, 146.0: 1}, 21: {0.0: 0}, 137: {0.0: 0}, 165: {0.0: 0}, 33: {0.0: 0}, 92: {0.0: 0}, 229: {0.0: 0, 23.0: 1}, 252: {0.0: 0}, 197: {0.0: 0}, 361: {0.0: 0}, 65: {0.0: 0}, 97: {0.0: 0, 64.0: 1, 121.0: 2}, 665: {0.0: 0, 25.0: 1, 71.0: 2, 173.0: 3}, 224: {0.0: 0}, 615: {0.0: 0}, 9: {0.0: 0}, 53: {0.0: 0}, 169: {0.0: 0}, 141: {0.0: 0}, 420: {0.0: 0}, 109: {0.0: 0}, 256: {0.0: 0}, 225: {0.0: 0}, 339: {0.0: 0}, 77: {0.0: 0}, 193: {0.0: 0}, 669: {0.0: 0}, 476: {0.0: 0}, 642: {0.0: 0}, 590: {0.0: 0}, 679: {0.0: 0, 239.0: 1, 251.0: 2}, 96: {0.0: 0, 247.0: 1}, 393: {0.0: 0}, 647: {0.0: 0}, 173: {0.0: 0}, 13: {0.0: 0}, 41: {0.0: 0}, 503: {0.0: 0}, 134: {0.0: 0}, 73: {0.0: 0}, 105: {0.0: 0}, 2: {0.0: 0}, 311: {0.0: 0}, 558: {0.0: 0}, 674: {0.0: 0}, 530: {0.0: 0}, 586: {0.0: 0}, 618: {0.0: 0}, 166: {0.0: 0}, 32: {0.0: 0}, 34: {0.0: 0}, 148: {0.0: 0, 71.0: 1, 251.0: 2}, 45: {0.0: 0}, 279: {0.0: 0}, 64: {0.0: 0}, 17: {0.0: 0}, 584: {0.0: 0}, 562: {0.0: 0}, 423: {0.0: 0}, 191: {0.0: 0, 250.0: 1}, 22: {0.0: 0}, 44: {0.0: 0}, 59: {0.0: 0}, 118: {0.0: 0}, 281: {0.0: 0}, 27: {0.0: 0}, 641: {0.0: 0}, 71: {0.0: 0}, 391: {0.0: 0}, 12: {0.0: 0}, 445: {0.0: 0}, 54: {0.0: 0}, 611: {0.0: 0, 19.0: 1, 20.0: 2, 29.0: 3}, 144: {0.0: 0}, 49: {0.0: 0}, 335: {0.0: 0}, 86: {0.0: 0}, 672: {0.0: 0}, 172: {0.0: 0}, 113: {0.0: 0}, 219: {0.0: 0, 18.0: 1, 20.0: 2, 250.0: 3}, 419: {0.0: 0}, 81: {0.0: 0}, 362: {0.0: 0}, 451: {0.0: 0}, 76: {0.0: 0}, 7: {0.0: 0}, 39: {0.0: 0}, 649: {0.0: 0, 83.0: 1}, 98: {0.0: 0, 70.0: 1, 191.0: 2}, 616: {0.0: 0}, 477: {0.0: 0}, 367: {0.0: 0}, 535: {0.0: 0}, 103: {0.0: 0}, 140: {0.0: 0}, 621: {0.0: 0, 82.0: 1, 236.0: 2}, 91: {0.0: 0}, 66: {0.0: 0}, 251: {0.0: 0}, 668: {0.0: 0}, 198: {0.0: 0}, 108: {0.0: 0}, 278: {0.0: 0}, 223: {0.0: 0}, 394: {0.0: 0}, 306: {0.0: 0}, 135: {0.0: 0}, 563: {0.0: 0}, 226: {0.0: 0}, 3: {0.0: 0}, 505: {0.0: 0}, 80: {0.0: 0}, 167: {0.0: 0}, 35: {0.0: 0}, 473: {0.0: 0}, 675: {0.0: 0}, 589: {0.0: 0}, 531: {0.0: 0}, 255: {0.0: 0}, 648: {0.0: 0}, 112: {0.0: 0}, 617: {0.0: 0}, 194: {0.0: 0}, 145: {0.0: 0}, 48: {0.0: 0}, 557: {0.0: 0}, 63: {0.0: 0}, 640: {0.0: 0}, 18: {0.0: 0}, 282: {0.0: 0}, 95: {0.0: 0, 56.0: 1}, 310: {0.0: 0}, 50: {0.0: 0}, 67: {0.0: 0}, 199: {0.0: 0}, 673: {0.0: 0}, 16: {0.0: 0}, 585: {0.0: 0}, 502: {0.0: 0}, 338: {0.0: 0}, 643: {0.0: 0}, 31: {0.0: 0}, 336: {0.0: 0}, 613: {0.0: 0}, 11: {0.0: 0}, 72: {0.0: 0}, 446: {0.0: 0}, 612: {0.0: 0}, 143: {0.0: 0}, 43: {0.0: 0}, 250: {0.0: 0}, 450: {0.0: 0}, 99: {0.0: 0, 70.0: 1, 166.0: 2, 255.0: 3}, 363: {0.0: 0}, 87: {0.0: 0}, 671: {0.0: 0}, 104: {0.0: 0}, 368: {0.0: 0}, 588: {0.0: 0}, 40: {0.0: 0}, 26: {0.0: 0}, 390: {0.0: 0}, 55: {0.0: 0}, 114: {0.0: 0}, 171: {0.0: 0}, 139: {0.0: 0}, 418: {0.0: 0}, 23: {0.0: 0}, 8: {0.0: 0}, 75: {0.0: 0}, 119: {0.0: 0, 85.0: 1}, 58: {0.0: 0}, 667: {0.0: 0}, 478: {0.0: 0}, 82: {0.0: 0}, 620: {0.0: 0, 62.0: 1}, 447: {0.0: 0}, 36: {0.0: 0}, 168: {0.0: 0}, 146: {0.0: 0, 82.0: 1}, 30: {0.0: 0}, 51: {0.0: 0}, 19: {0.0: 0}, 422: {0.0: 0}, 564: {0.0: 0, 9.0: 1, 20.0: 2, 73.0: 3}, 305: {0.0: 0}, 107: {0.0: 0}, 4: {0.0: 0}, 136: {0.0: 0}, 506: {0.0: 0}, 79: {0.0: 0}, 195: {0.0: 0}, 474: {0.0: 0}, 532: {0.0: 0}, 94: {0.0: 0}, 283: {0.0: 0}, 395: {0.0: 0}, 644: {0.0: 0}, 47: {0.0: 0}, 15: {0.0: 0}, 163: {0.0: 0, 85.0: 1}, 200: {0.0: 0}, 68: {0.0: 0}, 62: {0.0: 0}, 277: {0.0: 0}, 691: {0.0: 0, 36.0: 1, 73.0: 2}, 501: {0.0: 0}, 90: {0.0: 0}, 111: {0.0: 0}, 254: {0.0: 0}, 227: {0.0: 0}, 337: {0.0: 0}, 83: {0.0: 0}, 309: {0.0: 0}, 560: {0.0: 0}, 639: {0.0: 0}, 676: {0.0: 0}, 222: {0.0: 0}, 592: {0.0: 0, 73.0: 1}, 364: {0.0: 0}}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "# a. Name of Input Column\n",
    "input_column = featureIndexer_phuong.getInputCol()\n",
    "\n",
    "# b. Name of Output Column\n",
    "output_column = featureIndexer_phuong.getOutputCol()\n",
    "\n",
    "# c. Number of Features\n",
    "num_features = len(df_phuong.select(\"features\").first()[0])\n",
    "\n",
    "# d. Map of Categories\n",
    "# Get the VectorIndexerModel from the transformation\n",
    "vectorIndexer_model = featureIndexer_phuong.fit(df_phuong)\n",
    "# Get the category maps\n",
    "category_maps = vectorIndexer_model.categoryMaps\n",
    "\n",
    "# Print the information\n",
    "print(f\"Name of Input Column: {input_column}\")\n",
    "print(f\"Name of Output Column: {output_column}\")\n",
    "print(f\"Number of Features: {num_features}\")\n",
    "print(\"Map of Categories:\")\n",
    "print(category_maps)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. Split your original data into 65% for training and 35% for testing and store the training data into a data frame named training_phuong and testing_phuong respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in training set: 61\n",
      "Number of records in testing set: 39\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training (65%) and test (35%) sets\n",
    "training_phuong, testing_phuong = df_phuong.randomSplit([0.65, 0.35], seed=42)\n",
    "\n",
    "# Show the size of each DataFrame\n",
    "print(f\"Number of records in training set: {training_phuong.count()}\")\n",
    "print(f\"Number of records in testing set: {testing_phuong.count()}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. Create an estimator object that contains a decision tree classifier make sure to set the correct input and output columns you created during the transformation steps 4 & 5 above. Name the estimator DT_phuong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier\n",
    "DT_phuong = DecisionTreeClassifier(labelCol=\"indexedLabel_phuong\", featuresCol=\"indexedFeatures_phuong\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. Create a pipeline object with three stages the first two are the transformers you defined in steps 4 & 5 and the third is the decision tree estimator you defined in step 8. Name the pipeline object pipeline_phuong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Create a Pipeline with the three stages\n",
    "pipeline_phuong = Pipeline(stages=[labelIndexer_phuong, featureIndexer_phuong, DT_phuong])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. Fit the training data to the pipeline. Store the results into an object named model_phuong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "model_phuong = pipeline_phuong.fit(training_phuong)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "11. Using the model_phuong predict the testing data. Store the results into a dataframe named predictions_phuong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make predictions on the testing data\n",
    "predictions_phuong = model_phuong.transform(testing_phuong)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "12. Print the schema of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- indexedLabel_phuong: double (nullable = false)\n",
      " |-- indexedFeatures_phuong: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the predictions DataFrame\n",
    "predictions_phuong.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "13. Print the accuracy of your model and the test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Test Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Create a VectorIndexer with a handleInvalid parameter\n",
    "featureIndexer_phuong = VectorIndexer(inputCol=\"features_phuong\", outputCol=\"indexedFeatures_phuong\", maxCategories=4, handleInvalid=\"skip\")\n",
    "\n",
    "# Create an evaluator for accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel_phuong\", \n",
    "                                              predictionCol=\"prediction\", \n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = evaluator.evaluate(predictions_phuong)\n",
    "\n",
    "# Compute the test error\n",
    "test_error = 1 - accuracy\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Test Error: {test_error}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "14. Show the first 10 predictions with the actual labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|            features|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       1.0|(692,[124,125,126...|\n",
      "|  0.0|       1.0|(692,[126,127,128...|\n",
      "|  0.0|       1.0|(692,[126,127,128...|\n",
      "|  0.0|       1.0|(692,[126,127,128...|\n",
      "|  0.0|       1.0|(692,[127,128,129...|\n",
      "|  1.0|       0.0|(692,[123,124,125...|\n",
      "|  1.0|       0.0|(692,[123,124,125...|\n",
      "|  1.0|       0.0|(692,[124,125,126...|\n",
      "|  1.0|       0.0|(692,[124,125,126...|\n",
      "|  1.0|       0.0|(692,[126,127,128...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the columns of interest for the first 10 rows\n",
    "predictions_phuong.select(\"label\", \"prediction\", \"features\").show(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
